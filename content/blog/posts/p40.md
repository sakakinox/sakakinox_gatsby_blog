---
title: CPUのみの環境でstable-diffusionを動かす
date: 2023-10-20
published: true
tags: ["Machine Learning","develop","stable-diffusion"]
---

生成系AIが盛り上がっているので遊んでみたい。  
でもグラボはないという状況でできるところまでやってみた記録

## 出来上がったもの

![00000-1846197223](../image/p40/00000-1846197223.png)

```
2girl, master piece , best quality
Negative prompt: (worst quality:2) , (low quality:2) , (normal quality:2) , lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, extra hands, extra finger
Steps: 20, Sampler: DPM++ SDE Karras, CFG scale: 7, Seed: 1846197223, Size: 512x512, Model hash: 7f96a1a9ca, Model: AnythingV5Ink_v5PrtRE, RNG: CPU, Version: v1.6.0-2-g4afaaf8a
```



## 環境

- CPU Intel i7 6700K

- Memory 16GB

- OS Ubuntu 20.04 -> 22.04

- その他　LXD上で動かす(自宅サーバーの仕様)

- AUTOMATIC1111/stable-diffusion-webui 

  <OgpLink url="https://github.com/AUTOMATIC1111/stable-diffusion-webui" />

## 環境構築の前に

stable-diffusion-webuiがpython3.10を要求しているためホストサーバーのOSをUbuntu20.04からUbuntu22.04に上げた。
※既存のソフトの依存関係などはよく調査すること

```shell
sudo do-release-upgrade
```

```shell
cat /etc/lsb-release 
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=22.04
DISTRIB_CODENAME=jammy
DISTRIB_DESCRIPTION="Ubuntu 22.04.3 LTS"

python3 -V
Python 3.10.12
```

## LXDでUbuntu22.04の環境構築

### stable-diffusion用のコンテナを作る。

```shell
lxc launch images:ubuntu/22.04 stable-diffusion
```

### Zero-tierでローカルネット設定

```shell
curl -s 'https://raw.githubusercontent.com/zerotier/ZeroTierOne/master/doc/contact%40zerotier.com.gpg' | gpg --import && if z=$(curl -s 'https://install.zerotier.com/' | gpg); then echo "$z" | sudo bash; fi
zerotier-cli  join  xxxxxxxxxx
```

### アップデートと要りそうなパッケージをインストール

```shell
apt update
apt upgrade
apt install wget git python3 python3-venv python-is-python3
```

### 実行ユーザを作成

rootで動かすことを推奨していないので一般ユーザを作成した。

```shell
adduser sakakinox
```



## stable-diffusionのセットアップ

### ソースコードのダウンロードと必要なモジュールのインストール。
モジュールはCPU用のものをインストールする。

```shell
git clone --depth=1 --branch v1.2.1 https://github.com/AUTOMATIC1111/stable-diffusion-webui
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu
```

### web-user.shの書き換え
CPU利用のためのオプションなどを追加する。

```shell
export COMMANDLINE_ARGS="--listen --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu all controlnet --no-half --enable-insecure-extension-access"
export TORCH_COMMAND="pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
```

| オプション                         | 内容                                                         |
| ---------------------------------- | ------------------------------------------------------------ |
| --listen                           | ローカルネットのコンピュータからアクセスできるようになる。   |
| --skip-torch-cuda-test             | CUDA が正しく動作するかどうかはチェックしません。            |
| --upcast-sampling                  | --no-halfといっしょに使うメモリの利用量が減少してパフォーマンスが上がる。 |
| --no-half-vae                      | ビデオメモリ使用量は増大するが黒画像発生率が低減する。（お守り） |
| --use-cpu all controlnet           | CPUで動作させる。                                            |
| --no-half                          | 16 ビット浮動小数点演算を利用しない。                        |
| --enable-insecure-extension-access | 他のオプションに関係なく、[拡張機能] タブを有効にします。web-uiから拡張機能を設定することができるようにする。 |

### modelのインストール

今回インストールしたのは`anythingv5nijimix`モデルによっては利用に制限がある場合があるので注意。
配置場所は`stable-diffusion-webui/models/Stable-diffusion`となる。

<OgpLink url="https://civitai.com/models/110761/anythingv5nijimix" />

```shell
cd stable-diffusion-webui/models/Stable-diffusion
wget https://civitai.com/api/download/models/119438 -O anythingv5nijimixV125.kKh6.safetensors
```



## systemdでサーバー起動時にstable-diffusionを起動させる

/etc/systemd/system/automatic1111.service を作成してコンテナ起動時にstable-diffusionを自動起動させる。
※各pathとUser名などは環境に合わせて調整すること

```shell
[Unit]
Description=Stable Diffusion AUTOMATIC1111 Web UI service
After=network.target
StartLimitIntervalSec=0

[Service]
Type=simple
Restart=always
RestartSec=1
User=sakakinox
ExecStart=/usr/bin/env bash /home/sakakinox/stable-diffusion-webui/webui.sh
WorkingDirectory=/home/sakakinox/stable-diffusion-webui
StandardOutput=append:/var/log/sdwebui.log
StandardError=append:/var/log/sdwebui.log

[Install]
WantedBy=multi-user.target
```

設定の読み込みと動作確認と起動設定

```shell
systemctl daemon-reload        #読み込み
systemctl start automatic1111  #起動確認
systemctl stop automatic1111   #停止確認
systemctl enable automatic1111 #自動起動設定
```

## 動作所感

画像生成は一通りできる画像サイズは1024x1024までならこのスペックでも出力できる。ControlNetやLora、Refinerなども一通り動いた。
生成に関しては512x512で1枚3~5分1024x1024で1枚40~50分ほどでサーバーで実行して放って置く分にはあまり苦にならない。
使えます。
ずっと実行していても、ファイルサーバーや録画サーバーには特に影響はみられず手応えしかありません。
ただ、構図の作り込みやプロンプトの探求は生成時間がネックで難しい現状だ。また、Animatediffなどは永遠に終わらないし
Loraの作成はやる気にもならない。
このあたりはGPUがないと話にならないといった現状だ。
ただ、GPUはパソコンの部品の中でもっとも高額な部品の一つなので投資前に手持ちの環境でstable-diffusionを動作確認できることはすごいアドバンテージだし、大きい計算リソースがなくても程度の差はあれそれなりの画像が出力されるところは機械学習がだいぶ大衆以下されてきたのだと実感する。

## 参考

<OgpLink url="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-And-Settings" />
